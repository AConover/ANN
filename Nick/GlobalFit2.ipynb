{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try:\n",
    "\n",
    "Model on entire dataset, model uncertainty estimated by smearing entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as optimization\n",
    "\n",
    "from BHDVCStf import BHDVCS #modified bhdvcs file\n",
    "bhdvcs = BHDVCS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DvcsData(object):\n",
    "    def __init__(self, df):\n",
    "        self.X = df.loc[:, ['phi_x', 'k', 'QQ', 'x_b', 't', 'F1', 'F2', 'ReH', 'ReE', 'ReHtilde', 'dvcs']]\n",
    "        self.XnoCFF = df.loc[:, ['phi_x', 'k', 'QQ', 'x_b', 't', 'F1', 'F2', 'dvcs']]\n",
    "        self.y = df.loc[:, 'F']\n",
    "        self.Kinematics = df.loc[:, ['k', 'QQ', 'x_b', 't']]\n",
    "        self.erry = df.loc[:, 'errF']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def getSet(self, setNum, itemsInSet=36):\n",
    "        pd.options.mode.chained_assignment = None\n",
    "        subX = self.X.loc[setNum*itemsInSet:(setNum+1)*itemsInSet-1, :]\n",
    "        subX['F'] = self.y.loc[setNum*itemsInSet:(setNum+1)*itemsInSet-1]\n",
    "        subX['errF'] = self.erry.loc[setNum*itemsInSet:(setNum+1)*itemsInSet-1]\n",
    "        pd.options.mode.chained_assignment = 'warn'\n",
    "        return DvcsData(subX)\n",
    "    \n",
    "    def sampleY(self):\n",
    "        return np.random.normal(self.y, self.erry)\n",
    "    \n",
    "    def sampleWeights(self):\n",
    "        return 1/self.erry\n",
    "    \n",
    "    def getAllKins(self, itemsInSets=36):\n",
    "        return self.Kinematics.iloc[np.array(range(len(df)//itemsInSets))*itemsInSets, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Set</th>\n",
       "      <th>index</th>\n",
       "      <th>k</th>\n",
       "      <th>QQ</th>\n",
       "      <th>x_b</th>\n",
       "      <th>t</th>\n",
       "      <th>phi_x</th>\n",
       "      <th>F</th>\n",
       "      <th>errF</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>dvcs</th>\n",
       "      <th>ReH</th>\n",
       "      <th>ReE</th>\n",
       "      <th>ReHtilde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058205</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>10</td>\n",
       "      <td>0.055596</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>20</td>\n",
       "      <td>0.066353</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>30</td>\n",
       "      <td>0.068655</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>40</td>\n",
       "      <td>0.072765</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>310</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>320</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>330</td>\n",
       "      <td>0.024191</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>340</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>350</td>\n",
       "      <td>0.020891</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #Set  index     k       QQ       x_b         t  phi_x         F  \\\n",
       "0       0      0  3.75  1.74013  0.435095 -0.380868      0  0.058205   \n",
       "1       0      1  3.75  1.74013  0.435095 -0.380868     10  0.055596   \n",
       "2       0      2  3.75  1.74013  0.435095 -0.380868     20  0.066353   \n",
       "3       0      3  3.75  1.74013  0.435095 -0.380868     30  0.068655   \n",
       "4       0      4  3.75  1.74013  0.435095 -0.380868     40  0.072765   \n",
       "..    ...    ...   ...      ...       ...       ...    ...       ...   \n",
       "535    14     31  7.75  2.63258  0.345012 -0.361188    310  0.023981   \n",
       "536    14     32  7.75  2.63258  0.345012 -0.361188    320  0.025345   \n",
       "537    14     33  7.75  2.63258  0.345012 -0.361188    330  0.024191   \n",
       "538    14     34  7.75  2.63258  0.345012 -0.361188    340  0.020530   \n",
       "539    14     35  7.75  2.63258  0.345012 -0.361188    350  0.020891   \n",
       "\n",
       "         errF        F1       F2      dvcs      ReH      ReE  ReHtilde  \n",
       "0    0.002910  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "1    0.002780  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "2    0.003318  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "3    0.003433  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "4    0.003638  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "..        ...       ...      ...       ...      ...      ...       ...  \n",
       "535  0.001199  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "536  0.001267  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "537  0.001210  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "538  0.001027  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "539  0.001045  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "\n",
       "[540 rows x 15 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dvcs_xs_newsets_genCFFs.csv\")\n",
    "data = DvcsData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSets = df['#Set'].max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce replicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using the baseline to fit replicas in this instance, but other methods can be easily substituted into the computeData function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seti = data.getSet(0)\n",
    "X = np.array(seti.XnoCFF)\n",
    "#(df.loc[:35, 'phi_x'], df.loc[:35, 'QQ'], df.loc[:35, 'x_b'], df.loc[:35, 't'], df.loc[:35, 'k'], constants)\n",
    "\n",
    "y = seti.sampleY()\n",
    "sigma = seti.erry\n",
    "pars0 = np.array([1, 1, 1]) #starting guesses for the parameters ReH, ReE, ReHTilde (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cff, cffcov = optimization.curve_fit(bhdvcs.TotalUUXS, X, y, pars0, sigma, method='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numReplicas = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeData(numSets, numReplicas):\n",
    "    results = []\n",
    "    for i in tqdm(range(numSets)):\n",
    "        replicas = []\n",
    "        seti = data.getSet(i)\n",
    "        X = np.array(seti.XnoCFF)\n",
    "        sigma = seti.erry\n",
    "        for i in range(numReplicas):\n",
    "            y = seti.sampleY()\n",
    "            cff, cffcov = optimization.curve_fit(bhdvcs.TotalUUXS, X, y, pars0, sigma, method='lm')\n",
    "            replicas.append(cff)\n",
    "        results.append(replicas)\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [03:34<00:00, 14.28s/it]\n"
     ]
    }
   ],
   "source": [
    "results = computeData(numSets, numReplicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Set</th>\n",
       "      <th>index</th>\n",
       "      <th>k</th>\n",
       "      <th>QQ</th>\n",
       "      <th>x_b</th>\n",
       "      <th>t</th>\n",
       "      <th>phi_x</th>\n",
       "      <th>F</th>\n",
       "      <th>errF</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>dvcs</th>\n",
       "      <th>ReH</th>\n",
       "      <th>ReE</th>\n",
       "      <th>ReHtilde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058205</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>10</td>\n",
       "      <td>0.055596</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>20</td>\n",
       "      <td>0.066353</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>30</td>\n",
       "      <td>0.068655</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "      <td>40</td>\n",
       "      <td>0.072765</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.498060</td>\n",
       "      <td>0.68579</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>13.0554</td>\n",
       "      <td>-53.0554</td>\n",
       "      <td>7.25302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>310</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>320</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>330</td>\n",
       "      <td>0.024191</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>340</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "      <td>350</td>\n",
       "      <td>0.020891</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.512913</td>\n",
       "      <td>0.71481</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>11.7411</td>\n",
       "      <td>-51.7411</td>\n",
       "      <td>6.52283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #Set  index     k       QQ       x_b         t  phi_x         F  \\\n",
       "0       0      0  3.75  1.74013  0.435095 -0.380868      0  0.058205   \n",
       "1       0      1  3.75  1.74013  0.435095 -0.380868     10  0.055596   \n",
       "2       0      2  3.75  1.74013  0.435095 -0.380868     20  0.066353   \n",
       "3       0      3  3.75  1.74013  0.435095 -0.380868     30  0.068655   \n",
       "4       0      4  3.75  1.74013  0.435095 -0.380868     40  0.072765   \n",
       "..    ...    ...   ...      ...       ...       ...    ...       ...   \n",
       "535    14     31  7.75  2.63258  0.345012 -0.361188    310  0.023981   \n",
       "536    14     32  7.75  2.63258  0.345012 -0.361188    320  0.025345   \n",
       "537    14     33  7.75  2.63258  0.345012 -0.361188    330  0.024191   \n",
       "538    14     34  7.75  2.63258  0.345012 -0.361188    340  0.020530   \n",
       "539    14     35  7.75  2.63258  0.345012 -0.361188    350  0.020891   \n",
       "\n",
       "         errF        F1       F2      dvcs      ReH      ReE  ReHtilde  \n",
       "0    0.002910  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "1    0.002780  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "2    0.003318  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "3    0.003433  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "4    0.003638  0.498060  0.68579  0.012288  13.0554 -53.0554   7.25302  \n",
       "..        ...       ...      ...       ...      ...      ...       ...  \n",
       "535  0.001199  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "536  0.001267  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "537  0.001210  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "538  0.001027  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "539  0.001045  0.512913  0.71481  0.012288  11.7411 -51.7411   6.52283  \n",
       "\n",
       "[540 rows x 15 columns]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 100, 3)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.800799235205227"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05401130923662351"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trues[i] - pred)/pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set #0 mean:  13.800799235205227\n",
      "Set #0 std:  1.072511071154321\n",
      "Set #0 true:  13.0554\n",
      "Set #0 pct_err:  -0.05401130923662351\n",
      "\n",
      "Set #1 mean:  11.677016811385558\n",
      "Set #1 std:  2.7614091243685293\n",
      "Set #1 true:  12.5549\n",
      "Set #1 pct_err:  0.07518043373530736\n",
      "\n",
      "Set #2 mean:  6.509762702327444\n",
      "Set #2 std:  2.729667045085954\n",
      "Set #2 true:  7.224239999999999\n",
      "Set #2 pct_err:  0.10975473766764303\n",
      "\n",
      "Set #3 mean:  8.682071533633646\n",
      "Set #3 std:  2.6607695078274665\n",
      "Set #3 true:  7.6527199999999995\n",
      "Set #3 pct_err:  -0.11856059117297314\n",
      "\n",
      "Set #4 mean:  11.800206432946293\n",
      "Set #4 std:  1.3020879371790532\n",
      "Set #4 true:  12.5549\n",
      "Set #4 pct_err:  0.0639559630877808\n",
      "\n",
      "Set #5 mean:  6.686582038552131\n",
      "Set #5 std:  1.9382663760209313\n",
      "Set #5 true:  7.224239999999999\n",
      "Set #5 pct_err:  0.08040848947159396\n",
      "\n",
      "Set #6 mean:  10.170263863848666\n",
      "Set #6 std:  3.203473513225569\n",
      "Set #6 true:  11.7411\n",
      "Set #6 pct_err:  0.1544538231436694\n",
      "\n",
      "Set #7 mean:  9.104678432077863\n",
      "Set #7 std:  2.565340214573919\n",
      "Set #7 true:  7.6527199999999995\n",
      "Set #7 pct_err:  -0.15947388399378085\n",
      "\n",
      "Set #8 mean:  11.806504767779467\n",
      "Set #8 std:  0.745059895180688\n",
      "Set #8 true:  12.5549\n",
      "Set #8 pct_err:  0.0633883818234623\n",
      "\n",
      "Set #9 mean:  7.978446516911765\n",
      "Set #9 std:  1.2492853794588084\n",
      "Set #9 true:  6.990139999999999\n",
      "Set #9 pct_err:  -0.12387204887779477\n",
      "\n",
      "Set #10 mean:  6.820650174653004\n",
      "Set #10 std:  1.4954348342095407\n",
      "Set #10 true:  7.224239999999999\n",
      "Set #10 pct_err:  0.059171752694020516\n",
      "\n",
      "Set #11 mean:  10.183245970233424\n",
      "Set #11 std:  2.263134401267512\n",
      "Set #11 true:  11.7411\n",
      "Set #11 pct_err:  0.1529820682246435\n",
      "\n",
      "Set #12 mean:  8.227264906744399\n",
      "Set #12 std:  1.1784948222954903\n",
      "Set #12 true:  6.990139999999999\n",
      "Set #12 pct_err:  -0.15036891613034745\n",
      "\n",
      "Set #13 mean:  6.891528704598663\n",
      "Set #13 std:  1.7501046084767555\n",
      "Set #13 true:  7.224239999999999\n",
      "Set #13 pct_err:  0.04827830074614946\n",
      "\n",
      "Set #14 mean:  10.75222220158665\n",
      "Set #14 std:  1.6863066412706198\n",
      "Set #14 true:  11.7411\n",
      "Set #14 pct_err:  0.09196962077917499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trues = df.loc[np.array(range(numSets))*36, 'ReH'].reset_index(drop=True)\n",
    "pct_errs_locals = []\n",
    "\n",
    "for i in range(numSets):\n",
    "    pred = results[i, :, 0].mean()\n",
    "    print('Set #' + str(i) + ' mean: ', pred)\n",
    "    print('Set #' + str(i) + ' std: ', results[i, :, 0].std())\n",
    "    print('Set #' + str(i) + ' true: ', trues[i])\n",
    "    pct_errs_locals.append((trues[i] - pred)/pred)\n",
    "    print('Set #' + str(i) + ' pct_err: ', pct_errs_locals[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019550454797461703"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pct_errs_locals).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of results = (# of Kinematic Sets, # of Replicas, 3 CFFs)\n",
    "\n",
    "CFFs are in order of: ReH, ReE, ReHtilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 100, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinematics = tf.keras.Input(shape=(4))\n",
    "x = tf.keras.layers.Dense(20, activation=\"tanh\")(kinematics)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "globalModel = tf.keras.Model(inputs=kinematics, outputs=outputs, name=\"GlobalModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(globalModel, \"cffs.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReH model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichCFF = 0 # ReH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[np.array(range(numSets))*36, ['k', 'QQ', 'x_b', 't']].reset_index(drop=True)\n",
    "\n",
    "y = df.loc[np.array(range(numSets))*36, 'ReH'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceEstimates(replica_models, valid_x):\n",
    "    cffGuesses = []\n",
    "    for model in replica_models:\n",
    "        cffGuesses.append(model.predict(valid_x)[0][0])\n",
    "    return np.array(cffGuesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>QQ</th>\n",
       "      <th>x_b</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.75</td>\n",
       "      <td>1.74013</td>\n",
       "      <td>0.435095</td>\n",
       "      <td>-0.380868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.75</td>\n",
       "      <td>2.03646</td>\n",
       "      <td>0.415563</td>\n",
       "      <td>-0.373495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.75</td>\n",
       "      <td>2.17955</td>\n",
       "      <td>0.385579</td>\n",
       "      <td>-0.283318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.75</td>\n",
       "      <td>2.07387</td>\n",
       "      <td>0.436939</td>\n",
       "      <td>-0.291599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.75</td>\n",
       "      <td>2.03646</td>\n",
       "      <td>0.415563</td>\n",
       "      <td>-0.373495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.75</td>\n",
       "      <td>2.17955</td>\n",
       "      <td>0.385579</td>\n",
       "      <td>-0.283318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.75</td>\n",
       "      <td>2.07387</td>\n",
       "      <td>0.436939</td>\n",
       "      <td>-0.291599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.75</td>\n",
       "      <td>2.03646</td>\n",
       "      <td>0.415563</td>\n",
       "      <td>-0.373495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.75</td>\n",
       "      <td>1.95072</td>\n",
       "      <td>0.360829</td>\n",
       "      <td>-0.278690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.75</td>\n",
       "      <td>2.17955</td>\n",
       "      <td>0.385579</td>\n",
       "      <td>-0.283318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.75</td>\n",
       "      <td>1.95072</td>\n",
       "      <td>0.360829</td>\n",
       "      <td>-0.278690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.75</td>\n",
       "      <td>2.17955</td>\n",
       "      <td>0.385579</td>\n",
       "      <td>-0.283318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.75</td>\n",
       "      <td>2.63258</td>\n",
       "      <td>0.345012</td>\n",
       "      <td>-0.361188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k       QQ       x_b         t\n",
       "0   3.75  1.74013  0.435095 -0.380868\n",
       "1   3.75  2.03646  0.415563 -0.373495\n",
       "2   4.75  2.17955  0.385579 -0.283318\n",
       "3   4.75  2.07387  0.436939 -0.291599\n",
       "4   4.75  2.03646  0.415563 -0.373495\n",
       "5   5.75  2.17955  0.385579 -0.283318\n",
       "6   5.75  2.63258  0.345012 -0.361188\n",
       "7   5.75  2.07387  0.436939 -0.291599\n",
       "8   5.75  2.03646  0.415563 -0.373495\n",
       "9   6.75  1.95072  0.360829 -0.278690\n",
       "10  6.75  2.17955  0.385579 -0.283318\n",
       "11  6.75  2.63258  0.345012 -0.361188\n",
       "12  7.75  1.95072  0.360829 -0.278690\n",
       "13  7.75  2.17955  0.385579 -0.283318\n",
       "14  7.75  2.63258  0.345012 -0.361188"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.97994061, 0.        ],\n",
       "       [0.        , 0.33204101, 0.76746766, 0.07215839],\n",
       "       [0.25      , 0.49237492, 0.44129581, 0.95470649],\n",
       "       [0.25      , 0.37395933, 1.        , 0.87366165],\n",
       "       [0.25      , 0.33204101, 0.76746766, 0.07215839],\n",
       "       [0.5       , 0.49237492, 0.44129581, 0.95470649],\n",
       "       [0.5       , 1.        , 0.        , 0.19260506],\n",
       "       [0.5       , 0.37395933, 1.        , 0.87366165],\n",
       "       [0.5       , 0.33204101, 0.76746766, 0.07215839],\n",
       "       [0.75      , 0.2359684 , 0.17206044, 1.        ],\n",
       "       [0.75      , 0.49237492, 0.44129581, 0.95470649],\n",
       "       [0.75      , 1.        , 0.        , 0.19260506],\n",
       "       [1.        , 0.2359684 , 0.17206044, 1.        ],\n",
       "       [1.        , 0.49237492, 0.44129581, 0.95470649],\n",
       "       [1.        , 1.        , 0.        , 0.19260506]])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rescaled = rescaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalModel.compile(optimizer=tf.keras.optimizers.Adam(.1), loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_weights = globalModel.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "\n",
    "valid_x = X_rescaled[[i], :]\n",
    "train_x = np.delete(X_rescaled, i, axis=0)\n",
    "valid_y = np.array(y[i])\n",
    "train_y = np.delete(np.array(y), i, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75      , 1.        , 0.        , 0.19260506]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalModel.set_weights(orig_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 - 0s - loss: 104.0302\n",
      "Epoch 2/150\n",
      "1/1 - 0s - loss: 70.3156\n",
      "Epoch 3/150\n",
      "1/1 - 0s - loss: 47.3932\n",
      "Epoch 4/150\n",
      "1/1 - 0s - loss: 29.9706\n",
      "Epoch 5/150\n",
      "1/1 - 0s - loss: 17.5446\n",
      "Epoch 6/150\n",
      "1/1 - 0s - loss: 10.6991\n",
      "Epoch 7/150\n",
      "1/1 - 0s - loss: 9.2779\n",
      "Epoch 8/150\n",
      "1/1 - 0s - loss: 11.4296\n",
      "Epoch 9/150\n",
      "1/1 - 0s - loss: 14.0019\n",
      "Epoch 10/150\n",
      "1/1 - 0s - loss: 14.7715\n",
      "Epoch 11/150\n",
      "1/1 - 0s - loss: 13.4791\n",
      "Epoch 12/150\n",
      "1/1 - 0s - loss: 11.0127\n",
      "Epoch 13/150\n",
      "1/1 - 0s - loss: 8.5088\n",
      "Epoch 14/150\n",
      "1/1 - 0s - loss: 6.8579\n",
      "Epoch 15/150\n",
      "1/1 - 0s - loss: 6.4576\n",
      "Epoch 16/150\n",
      "1/1 - 0s - loss: 7.1205\n",
      "Epoch 17/150\n",
      "1/1 - 0s - loss: 8.1964\n",
      "Epoch 18/150\n",
      "1/1 - 0s - loss: 8.9411\n",
      "Epoch 19/150\n",
      "1/1 - 0s - loss: 8.9164\n",
      "Epoch 20/150\n",
      "1/1 - 0s - loss: 8.1450\n",
      "Epoch 21/150\n",
      "1/1 - 0s - loss: 6.9914\n",
      "Epoch 22/150\n",
      "1/1 - 0s - loss: 5.9257\n",
      "Epoch 23/150\n",
      "1/1 - 0s - loss: 5.2996\n",
      "Epoch 24/150\n",
      "1/1 - 0s - loss: 5.2028\n",
      "Epoch 25/150\n",
      "1/1 - 0s - loss: 5.4483\n",
      "Epoch 26/150\n",
      "1/1 - 0s - loss: 5.6969\n",
      "Epoch 27/150\n",
      "1/1 - 0s - loss: 5.6542\n",
      "Epoch 28/150\n",
      "1/1 - 0s - loss: 5.2206\n",
      "Epoch 29/150\n",
      "1/1 - 0s - loss: 4.5143\n",
      "Epoch 30/150\n",
      "1/1 - 0s - loss: 3.7772\n",
      "Epoch 31/150\n",
      "1/1 - 0s - loss: 3.2286\n",
      "Epoch 32/150\n",
      "1/1 - 0s - loss: 2.9496\n",
      "Epoch 33/150\n",
      "1/1 - 0s - loss: 2.8580\n",
      "Epoch 34/150\n",
      "1/1 - 0s - loss: 2.7815\n",
      "Epoch 35/150\n",
      "1/1 - 0s - loss: 2.5766\n",
      "Epoch 36/150\n",
      "1/1 - 0s - loss: 2.2164\n",
      "Epoch 37/150\n",
      "1/1 - 0s - loss: 1.7911\n",
      "Epoch 38/150\n",
      "1/1 - 0s - loss: 1.4292\n",
      "Epoch 39/150\n",
      "1/1 - 0s - loss: 1.2004\n",
      "Epoch 40/150\n",
      "1/1 - 0s - loss: 1.0737\n",
      "Epoch 41/150\n",
      "1/1 - 0s - loss: 0.9559\n",
      "Epoch 42/150\n",
      "1/1 - 0s - loss: 0.7733\n",
      "Epoch 43/150\n",
      "1/1 - 0s - loss: 0.5311\n",
      "Epoch 44/150\n",
      "1/1 - 0s - loss: 0.2996\n",
      "Epoch 45/150\n",
      "1/1 - 0s - loss: 0.1482\n",
      "Epoch 46/150\n",
      "1/1 - 0s - loss: 0.0924\n",
      "Epoch 47/150\n",
      "1/1 - 0s - loss: 0.0970\n",
      "Epoch 48/150\n",
      "1/1 - 0s - loss: 0.1145\n",
      "Epoch 49/150\n",
      "1/1 - 0s - loss: 0.1176\n",
      "Epoch 50/150\n",
      "1/1 - 0s - loss: 0.1068\n",
      "Epoch 51/150\n",
      "1/1 - 0s - loss: 0.0995\n",
      "Epoch 52/150\n",
      "1/1 - 0s - loss: 0.1102\n",
      "Epoch 53/150\n",
      "1/1 - 0s - loss: 0.1392\n",
      "Epoch 54/150\n",
      "1/1 - 0s - loss: 0.1722\n",
      "Epoch 55/150\n",
      "1/1 - 0s - loss: 0.1912\n",
      "Epoch 56/150\n",
      "1/1 - 0s - loss: 0.1865\n",
      "Epoch 57/150\n",
      "1/1 - 0s - loss: 0.1616\n",
      "Epoch 58/150\n",
      "1/1 - 0s - loss: 0.1292\n",
      "Epoch 59/150\n",
      "1/1 - 0s - loss: 0.1024\n",
      "Epoch 60/150\n",
      "1/1 - 0s - loss: 0.0866\n",
      "Epoch 61/150\n",
      "1/1 - 0s - loss: 0.0785\n",
      "Epoch 62/150\n",
      "1/1 - 0s - loss: 0.0700\n",
      "Epoch 63/150\n",
      "1/1 - 0s - loss: 0.0560\n",
      "Epoch 64/150\n",
      "1/1 - 0s - loss: 0.0391\n",
      "Epoch 65/150\n",
      "1/1 - 0s - loss: 0.0268\n",
      "Epoch 66/150\n",
      "1/1 - 0s - loss: 0.0258\n",
      "Epoch 67/150\n",
      "1/1 - 0s - loss: 0.0352\n",
      "Epoch 68/150\n",
      "1/1 - 0s - loss: 0.0479\n",
      "Epoch 69/150\n",
      "1/1 - 0s - loss: 0.0557\n",
      "Epoch 70/150\n",
      "1/1 - 0s - loss: 0.0553\n",
      "Epoch 71/150\n",
      "1/1 - 0s - loss: 0.0493\n",
      "Epoch 72/150\n",
      "1/1 - 0s - loss: 0.0430\n",
      "Epoch 73/150\n",
      "1/1 - 0s - loss: 0.0389\n",
      "Epoch 74/150\n",
      "1/1 - 0s - loss: 0.0360\n",
      "Epoch 75/150\n",
      "1/1 - 0s - loss: 0.0319\n",
      "Epoch 76/150\n",
      "1/1 - 0s - loss: 0.0258\n",
      "Epoch 77/150\n",
      "1/1 - 0s - loss: 0.0197\n",
      "Epoch 78/150\n",
      "1/1 - 0s - loss: 0.0161\n",
      "Epoch 79/150\n",
      "1/1 - 0s - loss: 0.0161\n",
      "Epoch 80/150\n",
      "1/1 - 0s - loss: 0.0183\n",
      "Epoch 81/150\n",
      "1/1 - 0s - loss: 0.0205\n",
      "Epoch 82/150\n",
      "1/1 - 0s - loss: 0.0212\n",
      "Epoch 83/150\n",
      "1/1 - 0s - loss: 0.0205\n",
      "Epoch 84/150\n",
      "1/1 - 0s - loss: 0.0193\n",
      "Epoch 85/150\n",
      "1/1 - 0s - loss: 0.0185\n",
      "Epoch 86/150\n",
      "1/1 - 0s - loss: 0.0177\n",
      "Epoch 87/150\n",
      "1/1 - 0s - loss: 0.0165\n",
      "Epoch 88/150\n",
      "1/1 - 0s - loss: 0.0144\n",
      "Epoch 89/150\n",
      "1/1 - 0s - loss: 0.0119\n",
      "Epoch 90/150\n",
      "1/1 - 0s - loss: 0.0099\n",
      "Epoch 91/150\n",
      "1/1 - 0s - loss: 0.0089\n",
      "Epoch 92/150\n",
      "1/1 - 0s - loss: 0.0088\n",
      "Epoch 93/150\n",
      "1/1 - 0s - loss: 0.0091\n",
      "Epoch 94/150\n",
      "1/1 - 0s - loss: 0.0093\n",
      "Epoch 95/150\n",
      "1/1 - 0s - loss: 0.0093\n",
      "Epoch 96/150\n",
      "1/1 - 0s - loss: 0.0093\n",
      "Epoch 97/150\n",
      "1/1 - 0s - loss: 0.0094\n",
      "Epoch 98/150\n",
      "1/1 - 0s - loss: 0.0094\n",
      "Epoch 99/150\n",
      "1/1 - 0s - loss: 0.0091\n",
      "Epoch 100/150\n",
      "1/1 - 0s - loss: 0.0084\n",
      "Epoch 101/150\n",
      "1/1 - 0s - loss: 0.0075\n",
      "Epoch 102/150\n",
      "1/1 - 0s - loss: 0.0069\n",
      "Epoch 103/150\n",
      "1/1 - 0s - loss: 0.0064\n",
      "Epoch 104/150\n",
      "1/1 - 0s - loss: 0.0062\n",
      "Epoch 105/150\n",
      "1/1 - 0s - loss: 0.0061\n",
      "Epoch 106/150\n",
      "1/1 - 0s - loss: 0.0059\n",
      "Epoch 107/150\n",
      "1/1 - 0s - loss: 0.0058\n",
      "Epoch 108/150\n",
      "1/1 - 0s - loss: 0.0058\n",
      "Epoch 109/150\n",
      "1/1 - 0s - loss: 0.0059\n",
      "Epoch 110/150\n",
      "1/1 - 0s - loss: 0.0059\n",
      "Epoch 111/150\n",
      "1/1 - 0s - loss: 0.0058\n",
      "Epoch 112/150\n",
      "1/1 - 0s - loss: 0.0055\n",
      "Epoch 113/150\n",
      "1/1 - 0s - loss: 0.0053\n",
      "Epoch 114/150\n",
      "1/1 - 0s - loss: 0.0051\n",
      "Epoch 115/150\n",
      "1/1 - 0s - loss: 0.0049\n",
      "Epoch 116/150\n",
      "1/1 - 0s - loss: 0.0048\n",
      "Epoch 117/150\n",
      "1/1 - 0s - loss: 0.0047\n",
      "Epoch 118/150\n",
      "1/1 - 0s - loss: 0.0046\n",
      "Epoch 119/150\n",
      "1/1 - 0s - loss: 0.0045\n",
      "Epoch 120/150\n",
      "1/1 - 0s - loss: 0.0045\n",
      "Epoch 121/150\n",
      "1/1 - 0s - loss: 0.0045\n",
      "Epoch 122/150\n",
      "1/1 - 0s - loss: 0.0045\n",
      "Epoch 123/150\n",
      "1/1 - 0s - loss: 0.0044\n",
      "Epoch 124/150\n",
      "1/1 - 0s - loss: 0.0043\n",
      "Epoch 125/150\n",
      "1/1 - 0s - loss: 0.0042\n",
      "Epoch 126/150\n",
      "1/1 - 0s - loss: 0.0042\n",
      "Epoch 127/150\n",
      "1/1 - 0s - loss: 0.0041\n",
      "Epoch 128/150\n",
      "1/1 - 0s - loss: 0.0040\n",
      "Epoch 129/150\n",
      "1/1 - 0s - loss: 0.0040\n",
      "Epoch 130/150\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 131/150\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 132/150\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 133/150\n",
      "1/1 - 0s - loss: 0.0039\n",
      "Epoch 134/150\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 135/150\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 136/150\n",
      "1/1 - 0s - loss: 0.0038\n",
      "Epoch 137/150\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 138/150\n",
      "1/1 - 0s - loss: 0.0037\n",
      "Epoch 139/150\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 140/150\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 141/150\n",
      "1/1 - 0s - loss: 0.0036\n",
      "Epoch 142/150\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 143/150\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 144/150\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 145/150\n",
      "1/1 - 0s - loss: 0.0035\n",
      "Epoch 146/150\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 147/150\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 148/150\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 149/150\n",
      "1/1 - 0s - loss: 0.0034\n",
      "Epoch 150/150\n",
      "1/1 - 0s - loss: 0.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15cda35b0>"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalModel.fit(train_x, train_y, epochs = 150, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testerWithTrue(globalModel, X, y, orig_weights, numSets):\n",
    "    '''\n",
    "    globalModel: a tensorflow neural network model\n",
    "    X: standardized kinematic variables\n",
    "    y: the true values of a CFF for each kinematic set\n",
    "    orig_weights: the original weights from when the model was created (used to reset model after it has been trained)\n",
    "    numSets: the number of kinematic sets\n",
    "    \n",
    "    returns: percent errors from each set\n",
    "    '''\n",
    "    pct_errors = []\n",
    "    for i in range(numSets):\n",
    "        valid_x = X[[i], :]\n",
    "        train_x = np.delete(X, i, axis=0)\n",
    "        valid_y = np.array(y[i])\n",
    "        train_y = np.delete(np.array(y), i, axis=0)\n",
    "        \n",
    "        globalModel.set_weights(orig_weights)\n",
    "        globalModel.fit(train_x, train_y, epochs = 150, verbose=0)\n",
    "        print(\"Set #:\", i)\n",
    "        pred = globalModel.predict(valid_x)[0][0]\n",
    "        print(\"Prediction: \", globalModel.predict(valid_x)[0][0])\n",
    "        print(\"True: \", valid_y)\n",
    "        pct_errors.append((valid_y - pred)/pred)\n",
    "        \n",
    "        print(\"Pct error\", pct_errors[-1])\n",
    "        print()\n",
    "    \n",
    "    return pct_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set #: 0\n",
      "Prediction:  12.611219\n",
      "True:  13.0554\n",
      "Pct error 0.03522106622427318\n",
      "\n",
      "Set #: 1\n",
      "Prediction:  12.225933\n",
      "True:  12.5549\n",
      "Pct error 0.026907306218028018\n",
      "\n",
      "Set #: 2\n",
      "Prediction:  7.322303\n",
      "True:  7.224239999999999\n",
      "Pct error -0.013392346742787395\n",
      "\n",
      "Set #: 3\n",
      "Prediction:  7.6507916\n",
      "True:  7.6527199999999995\n",
      "Pct error 0.00025204645995010363\n",
      "\n",
      "Set #: 4\n",
      "Prediction:  12.2219515\n",
      "True:  12.5549\n",
      "Pct error 0.027241845603557212\n",
      "\n",
      "Set #: 5\n",
      "Prediction:  7.2582135\n",
      "True:  7.224239999999999\n",
      "Pct error -0.0046807000036856805\n",
      "\n",
      "Set #: 6\n",
      "Prediction:  12.382097\n",
      "True:  11.7411\n",
      "Pct error -0.05176806736513922\n",
      "\n",
      "Set #: 7\n",
      "Prediction:  7.4622693\n",
      "True:  7.6527199999999995\n",
      "Pct error 0.02552181997228917\n",
      "\n",
      "Set #: 8\n",
      "Prediction:  12.218863\n",
      "True:  12.5549\n",
      "Pct error 0.027501534247353694\n",
      "\n",
      "Set #: 9\n",
      "Prediction:  6.8670454\n",
      "True:  6.990139999999999\n",
      "Pct error 0.017925409001642682\n",
      "\n",
      "Set #: 10\n",
      "Prediction:  7.24019\n",
      "True:  7.224239999999999\n",
      "Pct error -0.002202984877480229\n",
      "\n",
      "Set #: 11\n",
      "Prediction:  12.259086\n",
      "True:  11.7411\n",
      "Pct error -0.04225320466638246\n",
      "\n",
      "Set #: 12\n",
      "Prediction:  6.860874\n",
      "True:  6.990139999999999\n",
      "Pct error 0.018841013646091146\n",
      "\n",
      "Set #: 13\n",
      "Prediction:  7.284029\n",
      "True:  7.224239999999999\n",
      "Pct error -0.008208232957460185\n",
      "\n",
      "Set #: 14\n",
      "Prediction:  11.277779\n",
      "True:  11.7411\n",
      "Pct error 0.041082680366201836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pct_errs = testerWithTrue(globalModel, X_rescaled, y, orig_weights, numSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(pct_errs)*100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testerWithReplicas(model, X, y, results, orig_weights, numSets, numReplicas):\n",
    "    pct_errors = []\n",
    "    for i in range(numSets):\n",
    "        valid_x = X[[i], :]\n",
    "        train_x = np.delete(X, i, axis=0)\n",
    "        valid_y = np.array(y[i])\n",
    "        \n",
    "        preds = []\n",
    "        for rep in range(numReplicas):\n",
    "            train_y = np.delete(results[:, rep, whichCFF], i)\n",
    "            \n",
    "            model.set_weights(orig_weights)\n",
    "            model.fit(train_x, train_y, epochs = 150, verbose=0)\n",
    "            preds.append(model.predict(valid_x)[0][0])\n",
    "        \n",
    "        print(\"Set #: \", i)\n",
    "        pred = np.array(preds).mean()\n",
    "        print(\"Prediction: \", np.array(preds).mean())\n",
    "        print(\"True: \", valid_y)\n",
    "        print(\"Sigma: \", np.array(preds).std())\n",
    "        pct_errors.append((valid_y - pred)/pred)\n",
    "        \n",
    "        print(\"Pct error:\", pct_errors[-1])\n",
    "        print()\n",
    "    \n",
    "    return pct_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set #:  0\n",
      "Prediction:  11.405094\n",
      "True:  13.0554\n",
      "Sigma:  1.9109739\n",
      "Pct error 0.14469901186610243\n",
      "\n",
      "Set #:  1\n",
      "Prediction:  12.472812\n",
      "True:  12.5549\n",
      "Sigma:  1.1530839\n",
      "Pct error 0.006581379008036809\n",
      "\n",
      "Set #:  2\n",
      "Prediction:  7.8825536\n",
      "True:  7.224239999999999\n",
      "Sigma:  1.215654\n",
      "Pct error -0.0835152683653953\n",
      "\n",
      "Set #:  3\n",
      "Prediction:  9.091397\n",
      "True:  7.6527199999999995\n",
      "Sigma:  2.2128608\n",
      "Pct error -0.1582460033687118\n",
      "\n",
      "Set #:  4\n",
      "Prediction:  12.378905\n",
      "True:  12.5549\n",
      "Sigma:  1.1304146\n",
      "Pct error 0.014217307545486696\n",
      "\n",
      "Set #:  5\n",
      "Prediction:  7.4942694\n",
      "True:  7.224239999999999\n",
      "Sigma:  1.2976414\n",
      "Pct error -0.03603144718502499\n",
      "\n",
      "Set #:  6\n",
      "Prediction:  9.436088\n",
      "True:  11.7411\n",
      "Sigma:  2.2892709\n",
      "Pct error 0.24427628137173796\n",
      "\n",
      "Set #:  7\n",
      "Prediction:  8.742762\n",
      "True:  7.6527199999999995\n",
      "Sigma:  1.7753592\n",
      "Pct error -0.12467932448827106\n",
      "\n",
      "Set #:  8\n",
      "Prediction:  11.463702\n",
      "True:  12.5549\n",
      "Sigma:  1.7309426\n",
      "Pct error 0.09518720732132097\n",
      "\n",
      "Set #:  9\n",
      "Prediction:  7.229822\n",
      "True:  6.990139999999999\n",
      "Sigma:  1.3272328\n",
      "Pct error -0.03315187476932526\n",
      "\n",
      "Set #:  10\n",
      "Prediction:  7.767092\n",
      "True:  7.224239999999999\n",
      "Sigma:  1.1612933\n",
      "Pct error -0.06989130706898561\n",
      "\n",
      "Set #:  11\n",
      "Prediction:  9.798151\n",
      "True:  11.7411\n",
      "Sigma:  2.057445\n",
      "Pct error 0.1982975135354842\n",
      "\n",
      "Set #:  12\n",
      "Prediction:  7.4003596\n",
      "True:  6.990139999999999\n",
      "Sigma:  1.2179824\n",
      "Pct error -0.055432391270463864\n",
      "\n",
      "Set #:  13\n",
      "Prediction:  8.333104\n",
      "True:  7.224239999999999\n",
      "Sigma:  1.2547385\n",
      "Pct error -0.1330673559129187\n",
      "\n",
      "Set #:  14\n",
      "Prediction:  9.265356\n",
      "True:  11.7411\n",
      "Sigma:  2.197937\n",
      "Pct error 0.26720440305781623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pct_errs = testerWithReplicas(globalModel, X_rescaled, y, results, orig_weights, numSets, numReplicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31606046817588396"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.abs(pct_errs), np.abs(pct_errs_locals))[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictWithReplicas(model, X, y, to_pred, results, orig_weights, numSets, numReplicas):\n",
    "    train_x = np.delete(X, i, axis=0)\n",
    "    valid_y = np.array(y[i])\n",
    "\n",
    "    preds = []\n",
    "    for rep in range(numReplicas):\n",
    "        \n",
    "        train_y = results[:, rep, whichCFF]\n",
    "\n",
    "        model.set_weights(orig_weights)\n",
    "        model.fit(train_x, train_y, epochs = 150, verbose=0)\n",
    "        preds.append(model.predict(to_pred)[0][0])\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.97994061 0.        ]]\n",
      "Mean Estimate for set 0: 12.180599\n",
      "Sigma for set 0: 2.2131245\n",
      "Actual value for set 0: 13.0554\n",
      "\n",
      "\n",
      "[[0.         0.33204101 0.76746766 0.07215839]]\n",
      "Mean Estimate for set 1: 13.261892\n",
      "Sigma for set 1: 1.1061112\n",
      "Actual value for set 1: 12.5549\n",
      "\n",
      "\n",
      "[[0.25       0.49237492 0.44129581 0.95470649]]\n",
      "Mean Estimate for set 2: 10.064156\n",
      "Sigma for set 2: 2.474273\n",
      "Actual value for set 2: 7.224239999999999\n",
      "\n",
      "\n",
      "[[0.25       0.37395933 1.         0.87366165]]\n",
      "Mean Estimate for set 3: 8.266892\n",
      "Sigma for set 3: 1.999591\n",
      "Actual value for set 3: 7.6527199999999995\n",
      "\n",
      "\n",
      "[[0.25       0.33204101 0.76746766 0.07215839]]\n",
      "Mean Estimate for set 4: 10.995502\n",
      "Sigma for set 4: 1.3111411\n",
      "Actual value for set 4: 12.5549\n",
      "\n",
      "\n",
      "[[0.5        0.49237492 0.44129581 0.95470649]]\n",
      "Mean Estimate for set 5: 9.868537\n",
      "Sigma for set 5: 1.3655368\n",
      "Actual value for set 5: 7.224239999999999\n",
      "\n",
      "\n",
      "[[0.5        1.         0.         0.19260506]]\n",
      "Mean Estimate for set 6: 8.863461\n",
      "Sigma for set 6: 1.8099493\n",
      "Actual value for set 6: 11.7411\n",
      "\n",
      "\n",
      "[[0.5        0.37395933 1.         0.87366165]]\n",
      "Mean Estimate for set 7: 8.917481\n",
      "Sigma for set 7: 2.2160373\n",
      "Actual value for set 7: 7.6527199999999995\n",
      "\n",
      "\n",
      "[[0.5        0.33204101 0.76746766 0.07215839]]\n",
      "Mean Estimate for set 8: 8.623492\n",
      "Sigma for set 8: 1.9193633\n",
      "Actual value for set 8: 12.5549\n",
      "\n",
      "\n",
      "[[0.75       0.2359684  0.17206044 1.        ]]\n",
      "Mean Estimate for set 9: 10.458212\n",
      "Sigma for set 9: 1.1373094\n",
      "Actual value for set 9: 6.990139999999999\n",
      "\n",
      "\n",
      "[[0.75       0.49237492 0.44129581 0.95470649]]\n",
      "Mean Estimate for set 10: 8.892212\n",
      "Sigma for set 10: 0.93529695\n",
      "Actual value for set 10: 7.224239999999999\n",
      "\n",
      "\n",
      "[[0.75       1.         0.         0.19260506]]\n",
      "Mean Estimate for set 11: 7.830838\n",
      "Sigma for set 11: 1.0361958\n",
      "Actual value for set 11: 11.7411\n",
      "\n",
      "\n",
      "[[1.         0.2359684  0.17206044 1.        ]]\n",
      "Mean Estimate for set 12: 10.098521\n",
      "Sigma for set 12: 1.6155416\n",
      "Actual value for set 12: 6.990139999999999\n",
      "\n",
      "\n",
      "[[1.         0.49237492 0.44129581 0.95470649]]\n",
      "Mean Estimate for set 13: 8.688921\n",
      "Sigma for set 13: 1.1670421\n",
      "Actual value for set 13: 7.224239999999999\n",
      "\n",
      "\n",
      "[[1.         1.         0.         0.19260506]]\n",
      "Mean Estimate for set 14: 6.550927\n",
      "Sigma for set 14: 1.3124961\n",
      "Actual value for set 14: 11.7411\n",
      "\n",
      "\n",
      "Overall RMSE: 2.7484891093751656\n"
     ]
    }
   ],
   "source": [
    "replica_models = fitModelsReplicas(globalModel, X_rescaled, y, numSets, numReplicas, results, whichCFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate plot of ReH as a function of x_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = -.3\n",
    "QQ = 2\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "cint_mul = stats.t.ppf(1-0.025, numReplicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "upper_y = []\n",
    "lower_y = []\n",
    "for x_b in range(100):\n",
    "    x.append(x_b/100)\n",
    "    d = np.array([[k, QQ, x_b/100, t]])\n",
    "    estimates = produceEstimates(replica_models, d)\n",
    "    mean = estimates.mean()\n",
    "    std = estimates.std()\n",
    "    y.append(mean)\n",
    "    upper_y.append(mean + std*cint_mul)\n",
    "    lower_y.append(mean - std*cint_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, lower_y)\n",
    "plt.plot(x, y, color='black')\n",
    "plt.plot(x, upper_y, color='red')\n",
    "plt.title('95% confidence interval with point predictions')\n",
    "plt.ylabel(\"ReH\")\n",
    "plt.xlabel(\"x_b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fitModelsReplicas(globalModel, X, y, numSets, numReplicas, results, whichCFF):\n",
    "#     valid_error = 0\n",
    "\n",
    "#     for i in range(numSets):\n",
    "#         replica_models = []\n",
    "\n",
    "#         valid_x = X[[i], :]\n",
    "#         train_x = np.delete(X, 0, axis=0)\n",
    "#         valid_y = np.array(y[i])\n",
    "\n",
    "#         for rep in range(numReplicas):\n",
    "#             train_y = np.delete(results[:, rep, whichCFF], i) #the training y is the only data that changes\n",
    "\n",
    "#             thisModel = tf.keras.models.clone_model(globalModel)\n",
    "#             thisModel.compile(optimizer=tf.keras.optimizers.Adam(.1), loss=tf.keras.losses.MeanSquaredError())\n",
    "#             thisModel.fit(train_x, train_y, epochs = 150, verbose=0)\n",
    "            \n",
    "#             replica_models.append(thisModel)\n",
    "\n",
    "#         print(valid_x)\n",
    "#         guesses = produceEstimates(replica_models, valid_x)\n",
    "#         print(\"Mean Estimate for set \" + str(i) + \": \" + str(guesses.mean()))\n",
    "#         print(\"Sigma for set \" + str(i) + \": \" + str(guesses.std()))\n",
    "#         print(\"Actual value for set \" + str(i) + \": \" + str(valid_y))\n",
    "#         print(\"\\n\")\n",
    "#         valid_error += np.square(guesses.mean() - valid_y)\n",
    "\n",
    "#     print(\"Overall RMSE: \" + str(np.sqrt(valid_error/numSets)))\n",
    "    \n",
    "#     replica_models = []\n",
    "#     for rep in range(numReplicas):\n",
    "#         train_y = results[:, rep, whichCFF]\n",
    "\n",
    "#         thisModel = tf.keras.models.clone_model(globalModel)\n",
    "#         thisModel.compile(optimizer=tf.keras.optimizers.Adam(.1), loss=tf.keras.losses.MeanSquaredError())\n",
    "#         thisModel.fit(X, train_y, epochs = 150, verbose=0)\n",
    "\n",
    "#         replica_models.append(thisModel)\n",
    "            \n",
    "#     return replica_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py38Root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
